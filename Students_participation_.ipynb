{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuPysfqKwIurh7bFBv7D8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navam16/class-participation/blob/main/Students_participation_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install openai-whisper sentence-transformers\n",
        "\n",
        "# Import libraries\n",
        "import whisper\n",
        "import os\n",
        "from google.colab import files\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from termcolor import colored  # To enhance output readability\n",
        "\n",
        "# Load Models\n",
        "whisper_model = whisper.load_model(\"base\")  # Whisper for speech-to-text\n",
        "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # SBERT for similarity scoring\n"
      ],
      "metadata": {
        "id": "dQwZFh67JCYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_audio(role):\n",
        "    \"\"\"Prompts the user to upload an audio file and returns the file path.\"\"\"\n",
        "    print(colored(f\"\\n🎤 Upload the {role}'s audio:\", \"cyan\", attrs=[\"bold\"]))\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        return filename\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Transcribes audio using Whisper and returns text.\"\"\"\n",
        "    print(colored(\"🔍 Transcribing audio...\", \"yellow\"))\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    return result[\"text\"]\n"
      ],
      "metadata": {
        "id": "6Qtg668JJIu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload & Transcribe Professor's Audio\n",
        "prof_audio_path = upload_audio(\"Professor Audio\")\n",
        "professor_text = transcribe_audio(prof_audio_path)\n",
        "print(colored(\"\\n📚 Professor's Transcription:\", \"blue\", attrs=[\"bold\"]))\n",
        "print(colored(professor_text, \"light_blue\"))\n",
        "\n",
        "# Upload & Transcribe Student's Audio\n",
        "student_audio_path = upload_audio(\"student audio\")\n",
        "student_text = transcribe_audio(student_audio_path)\n",
        "print(colored(\"\\n🗣️ Student's Transcription:\", \"green\", attrs=[\"bold\"]))\n",
        "print(colored(student_text, \"light_green\"))\n"
      ],
      "metadata": {
        "id": "6UnFXb44JMvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_relevance(prof_text, student_text):\n",
        "    \"\"\"Calculates semantic similarity score between professor's and student's text.\"\"\"\n",
        "    print(colored(\"\\n🔍 Evaluating Student's Relevance...\", \"yellow\"))\n",
        "    prof_embedding = sbert_model.encode(prof_text, convert_to_tensor=True)\n",
        "    student_embedding = sbert_model.encode(student_text, convert_to_tensor=True)\n",
        "    score = util.pytorch_cos_sim(prof_embedding, student_embedding).item()\n",
        "    return round(score * 100, 2)  # Convert to percentage\n",
        "\n",
        "# Compute Score\n",
        "relevance_score = calculate_relevance(professor_text, student_text)\n",
        "\n",
        "# Display Final Score with Remarks\n",
        "print(colored(\"\\n📊 Student's Relevance Score: \", \"magenta\", attrs=[\"bold\"]), end=\"\")\n",
        "print(colored(f\"{relevance_score}/100\", \"light_magenta\", attrs=[\"bold\"]))\n",
        "\n",
        "# Provide feedback based on score\n",
        "if relevance_score > 85:\n",
        "    print(colored(\"\\n🌟 Excellent! The student stayed highly relevant to the topic.\", \"green\", attrs=[\"bold\"]))\n",
        "elif 60 <= relevance_score <= 85:\n",
        "    print(colored(\"\\n✅ Good effort! The student covered most of the key points.\", \"yellow\", attrs=[\"bold\"]))\n",
        "else:\n",
        "    print(colored(\"\\n⚠️ Needs Improvement! The response lacked alignment with the topic.\", \"red\", attrs=[\"bold\"]))\n"
      ],
      "metadata": {
        "id": "MO2Qu3U2JRuO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}